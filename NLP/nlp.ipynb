{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At',\n",
       " 'eight',\n",
       " \"o'clock\",\n",
       " 'on',\n",
       " 'Thursday',\n",
       " 'morning',\n",
       " '...',\n",
       " 'Arthur',\n",
       " 'did',\n",
       " \"n't\",\n",
       " 'feel',\n",
       " 'very',\n",
       " 'good',\n",
       " '.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"\"\"At eight o'clock on Thursday morning... Arthur didn't feel very good.\"\"\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('At', 'IN'),\n",
       " ('eight', 'CD'),\n",
       " (\"o'clock\", 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('Thursday', 'NNP'),\n",
       " ('morning', 'NN')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load trainer.py\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "import nltk\n",
    "import sys\n",
    "\n",
    "# Trains and saves a tagger model to a file\n",
    "# @filename name of file to save to\n",
    "# @train_set the tagged set to train on\n",
    "def train_and_save(filename, train_set):\n",
    "    outfile = open(filename, 'wb')\n",
    "    t = nltk.UnigramTagger(train_set)\n",
    "    dump(t, outfile, -1)\n",
    "    outfile.close()\n",
    "\n",
    "# Loads a tagger from file\n",
    "# @filename\n",
    "# @return tagger object\n",
    "def load_tagger(filename):\n",
    "    infile = open(filename, 'rb')\n",
    "    t = load(infile)\n",
    "    infile.close()\n",
    "    return t\n",
    "\n",
    "# Uncomment to train - Trains over ntlk brown corpus\n",
    "#brown_train = nltk.corpus.brown.tagged_sents()\n",
    "#train_and_save('models/brown_all.pkl',brown_train)\n",
    "\n",
    "# Loads tagger, loop will take in sentence and return list of tagged tokens\n",
    "\n",
    "def test_tagger():\n",
    "    t = load_tagger('models/brown_all.pkl')\n",
    "    while 1:\n",
    "        print(\"Enter command:\")\n",
    "        cmd = input()\n",
    "        tokens = nltk.word_tokenize(cmd)\n",
    "        t.tag(tokens)\n",
    "        tagged = t.tag(tokens)\n",
    "        print(tagged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load '../Statistics/statsop.py'\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "import fnmatch\n",
    "\n",
    "class StatsOp:\n",
    "   \n",
    "    #constructor\n",
    "    def __init__(self):\n",
    "        self.isInitialized = False\n",
    "        self.columns = []\n",
    "        self.rows = []\n",
    "        \n",
    "#<--------------- Table Operations --------------->\n",
    "    \n",
    "    #update value\n",
    "    def updateCell(self, col, row, value):\n",
    "        if self.isInitialized:\n",
    "            df = self.data\n",
    "            df.set_value(row, col, value)\n",
    "            self.data = df\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    #append value (row) into given column\n",
    "    def insertRow(self, col, value):\n",
    "        if self.isInitialized:\n",
    "            df = self.data\n",
    "            dfTemp = pd.DataFrame(df.iloc[[0]])\n",
    "            for i, row in dfTemp.iterrows():\n",
    "                for colName in list(df):\n",
    "                    dfTemp.loc[i, colName] = np.nan\n",
    "            dfTemp.set_value(0, col, value)\n",
    "            df = df.append(dfTemp)\n",
    "            df = df.reset_index(drop=True)\n",
    "            self.data = df\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "#<--------------- Getter & Setter Operations --------------->\n",
    "    #getter and setter for operation\n",
    "    def setOperation(self, op):\n",
    "        self.operation = op\n",
    "        \n",
    "    def getOperation(self):\n",
    "        return self.operation\n",
    " \n",
    "    \n",
    "    #getter & setter for the filename\n",
    "    def setFilename(self, fName):\n",
    "        self.fileName = fName\n",
    "    \n",
    "    def getFilename(self):\n",
    "        return self.fileName\n",
    "    \n",
    "    #reads in csv file into a dataframe and stores that df as data\n",
    "    #TODO: handle cases where the file is not in the format of csv...\n",
    "    def setData(self, fName):\n",
    "        #name.csv\n",
    "        hasExtension = fName.find(\".\")\n",
    "        status = False\n",
    "        if hasExtension < 0:\n",
    "            filename = fName + \".csv\"\n",
    "            for file in os.listdir('.'):\n",
    "                if fnmatch.fnmatch(file, '*.csv'):\n",
    "                    if filename == file:\n",
    "                        fName = filename\n",
    "                        status = True\n",
    "        else:\n",
    "            status = os.path.isfile(fName)\n",
    "\n",
    "        if status:\n",
    "            self.data = pd.read_csv(fName)\n",
    "            self.isInitialized = True\n",
    "        else:\n",
    "            print(\"404 File:\" + fName +\" Not Found!!!!!!!!!\")\n",
    "        self.isInitialized = status\n",
    "        return status\n",
    "    \n",
    "    \n",
    "    def getData(self):\n",
    "        if self.isInitialized:\n",
    "            return self.data\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        \n",
    "#<--------------- Querying Operations --------------->\n",
    "       \n",
    "    def checkInitialized(self):\n",
    "        return self.isInitialized\n",
    "    \n",
    "    #returns the mean for the given column\n",
    "    def calculateColumnMean(self,col):\n",
    "        df = self.data\n",
    "        mean = df[col].mean()\n",
    "        return mean\n",
    "    \n",
    "    #returns the mean for the given row\n",
    "    def calculateRowMean(self, row):\n",
    "        df = self.data\n",
    "        mean = df.iloc[row].mean()\n",
    "        return mean\n",
    "    \n",
    "    #returns an array of the mean for each column\n",
    "    def calculateColumnsMean(self):\n",
    "        if self.isInitialized:\n",
    "            dataframe = self.data\n",
    "            columns = self.columns\n",
    "            result = []\n",
    "            for col in columns:\n",
    "                mean = dataframe[col].mean()\n",
    "                result.append(mean)\n",
    "                print(col + \" \" + str(mean))\n",
    "            return result\n",
    "        else:\n",
    "            return None\n",
    "       \n",
    "    def describeColumn(self):\n",
    "        if self.isInitialized:\n",
    "            dataframe = self.data\n",
    "            columns = self.columns\n",
    "            result = []\n",
    "            for col in columns:\n",
    "                #description is a dataframe\n",
    "                description = dataframe[col].describe()\n",
    "                result.append(description)\n",
    "            return result\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "     #returns an array of the mean for each row\n",
    "    def calculateRowsMean(self):\n",
    "        if self.isInitialized:\n",
    "            dataframe = self.data\n",
    "            rows = self.rows\n",
    "            result = []\n",
    "            for row in rows:\n",
    "                mean = dataframe.iloc[row].mean()\n",
    "                result.append(mean)\n",
    "            return result\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        \n",
    "#<--------------- Print Operations --------------->\n",
    "\n",
    "    #print column\n",
    "    def printColumn(self,col):\n",
    "        if self.isInitialized:\n",
    "            df = self.data\n",
    "            print(df[col])\n",
    "        else:\n",
    "            print(\"No Data Available\")\n",
    "    \n",
    "    \n",
    "    #print row\n",
    "    def printRow(self,row):\n",
    "        if self.isInitialized:\n",
    "            df = self.data\n",
    "            print(df.iloc[[row]])\n",
    "        else:\n",
    "            print(\"No Data Available\")\n",
    "        \n",
    "    #List of all column and row names\n",
    "    def getColumnNames(self):\n",
    "        if self.isInitialized:\n",
    "            df = self.data\n",
    "            return list(df)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def getRowNames(self):\n",
    "        if self.isInitialized:\n",
    "            df = self.data\n",
    "            return list(df.index)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    \n",
    "#<--------------- Array Operations --------------->\n",
    "\n",
    "    #Unused for now...\n",
    "    \n",
    "    #getter & setter for columns\n",
    "    #set column array = array\n",
    "    def setColumns(self, cols):\n",
    "        self.columns = cols\n",
    "        \n",
    "    #add columns to the array\n",
    "    def addColumn(self, col):\n",
    "        self.columns.append(col)\n",
    "    \n",
    "    def getColumns(self):\n",
    "        return self.columns\n",
    "    \n",
    "    #getter & setter for row\n",
    "    #set array = array\n",
    "    def setRows(self, rows):\n",
    "        self.rows = rows\n",
    "    #add individual rows    \n",
    "    def addRow(self, row):\n",
    "        self.rows.append(row)\n",
    "        \n",
    "    def getRows(self):\n",
    "        return self.rows\n",
    "    \n",
    "#<--------------- Misc Operations --------------->\n",
    "   \n",
    "    #example function    \n",
    "    def testFunc(self):\n",
    "        return 'hello world'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load synthesis.py\n",
    "from nltk import word_tokenize\n",
    "from nltk import tag\n",
    "import sys\n",
    "import string\n",
    "\n",
    "import trainer\n",
    "# sys.path.insert(0, '../Statistics')\n",
    "# from statsop import StatsOp\n",
    "\n",
    "\n",
    "class Synthesizer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stats = StatsOp()\n",
    "        self.tagger = trainer.load_tagger('models/brown_all.pkl')\n",
    "\n",
    "        self.labels = {}\n",
    "        self.labels['verb'] = 'VB'\n",
    "        self.labels['noun'] = 'NN'\n",
    "\n",
    "        self.specialNouns = []\n",
    "        self.specialNouns.append('data')\n",
    "        self.specialNouns.append('row')\n",
    "        self.specialNouns.append('col')\n",
    "        self.specialNouns.append('column')\n",
    "        \n",
    "        self.commandStack = []\n",
    "\n",
    "    def tokenize(self, cmd):\n",
    "        return word_tokenize(cmd)\n",
    "\n",
    "    def tag(self, tokens):\n",
    "        return self.tagger.tag(tokens)\n",
    "\n",
    "    def synonym_look_up(self,word):\n",
    "        #check if word is in synonynm\n",
    "        #return the appropriatly mapped word\n",
    "        return word\n",
    "    \n",
    "    def print_requested (self, objs):\n",
    "        print(\"Printing Requested\")\n",
    "    \n",
    "        \n",
    "    # attempt to initialize stats\n",
    "    def read_data_cmd(self, tokens): \n",
    "        if tokens[0][0].lower() == 'read': #handles case of reading in data\n",
    "            # next argument must be filename, attempt to set up the data\n",
    "            if len(tokens) == 2:\n",
    "                return self.stats.setData(tokens[1][0])\n",
    "    \n",
    "    def print_data_cmd(self, tokens):\n",
    "        print (\"attempting to print..\")\n",
    "        command = self.build_command(tokens)\n",
    "        print(self.commandStack)\n",
    "        if tokens[0][0].lower() == 'show': # handles cases of printing or showing data\n",
    "            [print_requested(n) for n in self.commandStack]\n",
    "            \n",
    "    def run_data_cmd(self, tokens):\n",
    "        if tokens[0][0].lower() == 'command': # handles cases statistic commands on data\n",
    "            print(\"printing out requested data\")\n",
    "            \n",
    "\n",
    "    # parse a noun or none tag and see what it is\n",
    "    def parse_noun_or_none(self, nn):\n",
    "        val = None\n",
    "\n",
    "        # test if int\n",
    "        try:\n",
    "            val = int(nn)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        # test if int\n",
    "        try:\n",
    "            val = float(nn)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        # we now know val is a variable\n",
    "        if val is None: # check if nn is even a column or row name\n",
    "            pass\n",
    "\n",
    "    # checks to see if arg is a name inside list, row or col\n",
    "    # returns True if it is\n",
    "    def check_name_in_list(self, arg, li):\n",
    "        if arg in li:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def build_command(self, tokens):\n",
    "        command = []\n",
    "        previousNoun = False\n",
    "        for pair in tokens:\n",
    "            if(pair[1] == \"VB\"): #action to perform\n",
    "                command.append(pair[0])\n",
    "                self.commandStack.append(command)\n",
    "                command = []\n",
    "                \n",
    "            if(pair[1] == \"CD\" and previousNoun): #cardinal number (or location) after a given noun\n",
    "                command.append(pair[0])\n",
    "\n",
    "            if(pair[1][0] == \"N\"): #noun\n",
    "                command.append(pair[0])\n",
    "                previousNoun = True\n",
    "            else:\n",
    "                previousNoun = False\n",
    "            \n",
    "            if(pair[1] == \"CC\"):\n",
    "                self.commandStack.append(command)\n",
    "                command = []\n",
    "                \n",
    "        self.commandStack.append(command)\n",
    "    \n",
    "    def synthesize(self, tagged, cmd):\n",
    "        stats = self.stats\n",
    "        labels = self.labels\n",
    "\n",
    "        # check if we've already initialized\n",
    "        '''\n",
    "        if stats.checkInitialized():\n",
    "\n",
    "            # Check if cmd is a row or column\n",
    "            cols = stats.getColumnNames()\n",
    "            rows = stats.getRowNames()\n",
    "\n",
    "            if check_name_in_list(cmd, cols):\n",
    "                print('name found in cols')\n",
    "            elif check_name_in_list(cmd, rows):\n",
    "                print('name found in rows')\n",
    "        '''\n",
    "\n",
    "        # check if command \n",
    "        if tagged[0][1] == labels['verb']:\n",
    "            print(\"Processing Verb\")\n",
    "            # Try to interpret this as a read initialization command\n",
    "            if not stats.checkInitialized():\n",
    "                self.read_data_cmd(tagged)\n",
    "            else:\n",
    "                print(\"Trying a non read command\")\n",
    "                command = self.synonym_look_up(tagged[0][0].lower())\n",
    "                if command == \"show\":\n",
    "                    self.print_data_cmd(tagged)\n",
    "                pass # test printing column/row commands here?\n",
    "\n",
    "        if tagged[0][1] == labels['noun']:\n",
    "\n",
    "            print(\"Processing Noun\")\n",
    "            if not stats.checkInitialized():\n",
    "                pass\n",
    "            else:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize synthesizer\n",
    "s = Synthesizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter command:\n",
      "read dummydata\n",
      "[('read', 'VB'), ('dummydata', None)]\n",
      "Processing Verb\n",
      "Enter command:\n",
      "show me column 1 and column 2\n",
      "[('show', 'VB'), ('me', 'PPO'), ('column', 'NN'), ('1', 'CD'), ('and', 'CC'), ('column', 'NN'), ('2', 'CD')]\n",
      "Processing Verb\n",
      "Trying a non read command\n",
      "attempting to print..\n",
      "[['show'], ['column', '1'], ['column', '2']]\n",
      "['show']\n",
      "['column', '1']\n",
      "['column', '2']\n",
      "Enter command:\n"
     ]
    }
   ],
   "source": [
    "# Read commands\n",
    "while(1):\n",
    "    print('Enter command:')\n",
    "    cmd = input()\n",
    "    tokens = s.tokenize(cmd)\n",
    "    tagged = s.tag(tokens)\n",
    "\n",
    "    print(tagged)\n",
    "    s.synthesize(tagged, cmd)\n",
    "    if(cmd == \"quit\"):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
